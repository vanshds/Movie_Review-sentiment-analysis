{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ad599c-f625-4e47-9c48-aa30b95c166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccff2c0d-d849-41f9-ae3d-fb5636cd41f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('IMDB Dataset.csv')\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "792e6158-3a99-497c-b608-662eb46e0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']\n",
    "y = df['sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79ea28ee-7657-4c36-89fc-f6daf0378c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "718f7d4f-bb3d-42f8-bc90-425ee367e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in X:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    if len(token_list) < 2:\n",
    "           continue  \n",
    "    input_sequences.append(token_list[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77a62f03-a32d-46ed-8b16-b581daeff9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_sequence_len = max(len(seq) for seq in input_sequences)\n",
    "X = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bbe0945-0a6b-4175-a2a7-060c557ee5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 181ms/step - accuracy: 0.6952 - loss: 0.5458\n",
      "Epoch 2/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 191ms/step - accuracy: 0.9077 - loss: 0.2375\n",
      "Epoch 3/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 179ms/step - accuracy: 0.9510 - loss: 0.1429\n",
      "Epoch 4/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 175ms/step - accuracy: 0.9757 - loss: 0.0838\n",
      "Epoch 5/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 176ms/step - accuracy: 0.9893 - loss: 0.0436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fe21034260>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 10, input_length=max_sequence_len))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d08f7a63-6ffc-4f56-b37e-febc590ae00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence for sentiment prediction (or type 'exit' to stop):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Test the model with user input\n",
    "while True:\n",
    "    user_input = input(\"Enter a sentence for sentiment prediction (or type 'exit' to stop): \")\n",
    "\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Tokenize and pad user input\n",
    "    test_seq = tokenizer.texts_to_sequences([user_input])\n",
    "    test_pad = pad_sequences(test_seq, maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(test_pad)\n",
    "\n",
    "    # Interpret result\n",
    "    sentiment = \"Positive\" if prediction[0][0] > 0.5 else \"Negative\"\n",
    "    print(f\"Predicted Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30ae5414-9473-4ca0-b1eb-ed264b41a73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Streamlit App\n",
    "import streamlit as st\n",
    "\n",
    "# --- Custom CSS for background image and stylish layout ---\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    /* Set full page background image */\n",
    "    .stApp {\n",
    "        background-image: url('https://images.unsplash.com/photo-1537498425277-c283d32ef9db'); /* You can replace this URL with your own image */\n",
    "        background-size: cover;\n",
    "        background-position: center;\n",
    "        background-repeat: no-repeat;\n",
    "    }\n",
    "    \n",
    "    /* Stylish main card */\n",
    "    .main-card {\n",
    "        background-color: rgba(255, 255, 255, 0.9);\n",
    "        padding: 30px;\n",
    "        border-radius: 20px;\n",
    "        box-shadow: 4px 4px 20px rgba(0,0,0,0.3);\n",
    "        max-width: 700px;\n",
    "        margin: auto;\n",
    "        margin-top: 50px;\n",
    "    }\n",
    "\n",
    "    .title {\n",
    "        color: #ff4b4b;\n",
    "        font-size: 48px;\n",
    "        font-weight: bold;\n",
    "        text-align: center;\n",
    "        margin-bottom: 10px;\n",
    "    }\n",
    "\n",
    "    .subtext {\n",
    "        color: #1f77b4;\n",
    "        font-size: 20px;\n",
    "        text-align: center;\n",
    "        margin-bottom: 30px;\n",
    "    }\n",
    "\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# --- Page Content ---\n",
    "st.markdown('<div class=\"main-card\">', unsafe_allow_html=True)\n",
    "st.markdown('<div class=\"title\">üéâ Sentiment Analysis Chatbot üéâ</div>', unsafe_allow_html=True)\n",
    "st.markdown('<div class=\"subtext\">‚ú® Enter a movie review below and I will predict the sentiment! ‚ú®</div>', unsafe_allow_html=True)\n",
    "\n",
    "# User input\n",
    "user_input = st.text_area('üìù Your Movie Review:', '', height=150)\n",
    "\n",
    "if st.button('üîç Predict Sentiment'):\n",
    "    if user_input.strip() == '':\n",
    "        st.warning('‚ö†Ô∏è Please enter a review.')\n",
    "    else:\n",
    "        # Example: your trained TF-IDF vectorizer and classifier\n",
    "        user_input_vector = tf.transform([user_input])\n",
    "        prediction = clf.predict(user_input_vector)[0]\n",
    "\n",
    "        if prediction == 'positive':\n",
    "            st.success('üéâ **Predicted Sentiment:** Positive üòÄ')\n",
    "            st.balloons()\n",
    "        else:\n",
    "            st.error('üíî **Predicted Sentiment:** Negative üòû')\n",
    "\n",
    "st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d4c28-a404-43e1-ac4c-66beb48897a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
